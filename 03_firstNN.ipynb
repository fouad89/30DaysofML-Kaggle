{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_firstNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "13N9l3GasKfmKkW42lAMh4MhDvk30C8xY",
      "authorship_tag": "ABX9TyPe5wQNV2lrOwPdDICp5Oiu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fouad89/30DaysofML-Kaggle/blob/master/03_firstNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pio5vsDBS_XZ",
        "outputId": "8cf43e58-a0f5-42f6-f9ae-2dab991f5bd7"
      },
      "source": [
        "# reading data from google drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld-wUJZdTF37"
      },
      "source": [
        "\n",
        "# library imports\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import pandas_profiling as pp\n",
        "import os\n",
        "\n",
        "# preprocessing\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# modeling\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "# evaluation\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fru3wI4pT1mG"
      },
      "source": [
        "COMPETETION_PATH = \"/content/drive/MyDrive/30-days-of-ml-competition1\"\n",
        "TRAIN_DATA_PATH = \"/content/drive/MyDrive/30-days-of-ml-competition1/data/train.csv\"\n",
        "TEST_DATA_PATH = \"/content/drive/MyDrive/30-days-of-ml-competition1/data/test.csv\"\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/30-days-of-ml-competition1/output\""
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PttvF_mQXu0S",
        "outputId": "bd71d3a9-2d43-4044-d03d-98d7670779a0"
      },
      "source": [
        "def read_organise_data(train=TRAIN_DATA_PATH):\n",
        "    \"\"\"read the data from a path and splitting to features and target\n",
        "\n",
        "    Args:\n",
        "        train (path, optional): The path of training data file to. Defaults to TRAIN_DATA_PATH.\n",
        "\n",
        "    Returns:\n",
        "        X, y: X for features and y for target\n",
        "    \"\"\"\n",
        "    full_df = pd.read_csv(train, index_col=\"id\")\n",
        "    print(f\"Shape of Dataset: {full_df.shape}\")\n",
        "    return full_df\n",
        "\n",
        "df= read_organise_data()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Dataset: (300000, 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tuIOwQgW9hy"
      },
      "source": [
        "# dropping cont12\n",
        "df.drop('cont12', axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwrE5ZoEXHdN"
      },
      "source": [
        "y = df.target.copy()\n",
        "X = df.drop('target', axis=1).copy()"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZgBXSeiQnyR",
        "outputId": "e5cacf48-7260-4e3d-a454-b44f75a25fee"
      },
      "source": [
        "def create_num_cols(df=X):\n",
        "    return df.select_dtypes(exclude=\"object\").columns.to_list()\n",
        "def create_cat_cols(df=X):\n",
        "    return [cname for cname in df.columns if (df[cname].dtypes==\"object\")]\n",
        "\n",
        "num_cnames = create_num_cols(X)\n",
        "cat_cnames = create_cat_cols(X)\n",
        "all_cnames = num_cnames + cat_cnames\n",
        "\n",
        "print(f\"There are {len(num_cnames)} Numerical columns\")\n",
        "print(f\"There are {len(cat_cnames)} Categorical Columns\")\n",
        "print(f\"In total, there are {len(all_cnames)} columns\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 14 Numerical columns\n",
            "There are 10 Categorical Columns\n",
            "In total, there are 24 columns\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yw3x74kf3qko"
      },
      "source": [
        "# categorical columns transformation\n",
        "ordinal_encode = OrdinalEncoder()\n",
        "X[cat_cnames] = ordinal_encode.fit_transform(X[cat_cnames])\n",
        "# scaling numerical columns\n",
        "# scaler= StandardScaler()\n",
        "# X[num_cnames] = scaler.fit_transform(X[num_cnames])\n",
        "# X"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXI9rQ2KsVjv"
      },
      "source": [
        "# # hot encoding categorical columns\n",
        "# def oneHotEncode(df=X, colNames=cat_cnames):\n",
        "#     for cname in cat_cnames:\n",
        "#         dummies = pd.get_dummies(df[cname], prefix=cname)\n",
        "#         df = pd.concat([df, dummies], axis=1)\n",
        "#         # drop the encoded col\n",
        "#         df.drop([cname], axis=1, inplace=True)\n",
        "#     return df\n",
        "\n",
        "# # applying encoding\n",
        "# X = oneHotEncode()\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3P1iDFduPEE",
        "outputId": "9e92f81a-fbd4-4278-9f2c-8afbe9c98777"
      },
      "source": [
        "print(f\"Shape of data after encoding: {X.shape}\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data after encoding: (300000, 24)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9kHT38Kbqfl"
      },
      "source": [
        "# splitting \n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=1)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDVEnNGVQvZR",
        "outputId": "6b09a0d8-7620-4d5c-b222-a278f11ac4ff"
      },
      "source": [
        "## Modeling\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_dim=X.shape[1]))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "\n",
        "# output layer\n",
        "model.add(Dense(1, activation='linear'))\n",
        "# Compile the network :\n",
        "model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
        "model.summary()\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_21 (Dense)             (None, 128)               3200      \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 234,113\n",
            "Trainable params: 234,113\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Es0ZlwSTddv5"
      },
      "source": [
        "# adding callback\n",
        "checkpoint_name = os.path.join(OUTPUT_PATH,\"weights\",'Weights-{epoch:03d}--{val_loss:.5f}.hdf5') \n",
        "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wVhud8wZvFH",
        "outputId": "b1ec4eed-71bc-4076-e384-8ccf0aaec92e"
      },
      "source": [
        "#batch_size = int(X_train.shape[0] / 50)\n",
        "model.fit(X, y, epochs=50,validation_split=0.2,callbacks=callbacks_list)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "7500/7500 [==============================] - 52s 7ms/step - loss: 0.6495 - mean_absolute_error: 0.6495 - val_loss: 0.5900 - val_mean_absolute_error: 0.5900\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.59002, saving model to /content/drive/MyDrive/30-days-of-ml-competition1/output/weights/Weights-001--0.59002.hdf5\n",
            "Epoch 2/50\n",
            "7500/7500 [==============================] - 51s 7ms/step - loss: 0.5939 - mean_absolute_error: 0.5939 - val_loss: 0.5884 - val_mean_absolute_error: 0.5884\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.59002 to 0.58840, saving model to /content/drive/MyDrive/30-days-of-ml-competition1/output/weights/Weights-002--0.58840.hdf5\n",
            "Epoch 3/50\n",
            "7500/7500 [==============================] - 49s 7ms/step - loss: 0.5922 - mean_absolute_error: 0.5922 - val_loss: 0.5873 - val_mean_absolute_error: 0.5873\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.58840 to 0.58731, saving model to /content/drive/MyDrive/30-days-of-ml-competition1/output/weights/Weights-003--0.58731.hdf5\n",
            "Epoch 4/50\n",
            "7500/7500 [==============================] - 48s 6ms/step - loss: 0.5914 - mean_absolute_error: 0.5914 - val_loss: 0.5902 - val_mean_absolute_error: 0.5902\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.58731\n",
            "Epoch 5/50\n",
            "7500/7500 [==============================] - 48s 6ms/step - loss: 0.5911 - mean_absolute_error: 0.5911 - val_loss: 0.5871 - val_mean_absolute_error: 0.5871\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.58731 to 0.58712, saving model to /content/drive/MyDrive/30-days-of-ml-competition1/output/weights/Weights-005--0.58712.hdf5\n",
            "Epoch 6/50\n",
            "7500/7500 [==============================] - 50s 7ms/step - loss: 0.5904 - mean_absolute_error: 0.5904 - val_loss: 0.5891 - val_mean_absolute_error: 0.5891\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.58712\n",
            "Epoch 7/50\n",
            "7500/7500 [==============================] - 48s 6ms/step - loss: 0.5898 - mean_absolute_error: 0.5898 - val_loss: 0.5859 - val_mean_absolute_error: 0.5859\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.58712 to 0.58589, saving model to /content/drive/MyDrive/30-days-of-ml-competition1/output/weights/Weights-007--0.58589.hdf5\n",
            "Epoch 8/50\n",
            "7500/7500 [==============================] - 50s 7ms/step - loss: 0.5904 - mean_absolute_error: 0.5904 - val_loss: 0.5879 - val_mean_absolute_error: 0.5879\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.58589\n",
            "Epoch 9/50\n",
            "7500/7500 [==============================] - 48s 6ms/step - loss: 0.5901 - mean_absolute_error: 0.5901 - val_loss: 0.5872 - val_mean_absolute_error: 0.5872\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.58589\n",
            "Epoch 10/50\n",
            "7500/7500 [==============================] - 48s 6ms/step - loss: 0.5896 - mean_absolute_error: 0.5896 - val_loss: 0.5915 - val_mean_absolute_error: 0.5915\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.58589\n",
            "Epoch 11/50\n",
            "7500/7500 [==============================] - 50s 7ms/step - loss: 0.5898 - mean_absolute_error: 0.5898 - val_loss: 0.5859 - val_mean_absolute_error: 0.5859\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.58589\n",
            "Epoch 12/50\n",
            "7500/7500 [==============================] - 50s 7ms/step - loss: 0.5898 - mean_absolute_error: 0.5898 - val_loss: 0.5884 - val_mean_absolute_error: 0.5884\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.58589\n",
            "Epoch 13/50\n",
            "7500/7500 [==============================] - 50s 7ms/step - loss: 0.5896 - mean_absolute_error: 0.5896 - val_loss: 0.5872 - val_mean_absolute_error: 0.5872\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.58589\n",
            "Epoch 14/50\n",
            "7500/7500 [==============================] - 48s 6ms/step - loss: 0.5898 - mean_absolute_error: 0.5898 - val_loss: 0.5870 - val_mean_absolute_error: 0.5870\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.58589\n",
            "Epoch 15/50\n",
            "7500/7500 [==============================] - 46s 6ms/step - loss: 0.5897 - mean_absolute_error: 0.5897 - val_loss: 0.5934 - val_mean_absolute_error: 0.5934\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.58589\n",
            "Epoch 16/50\n",
            "7500/7500 [==============================] - 48s 6ms/step - loss: 0.5893 - mean_absolute_error: 0.5893 - val_loss: 0.5869 - val_mean_absolute_error: 0.5869\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.58589\n",
            "Epoch 17/50\n",
            "7500/7500 [==============================] - 46s 6ms/step - loss: 0.5893 - mean_absolute_error: 0.5893 - val_loss: 0.5851 - val_mean_absolute_error: 0.5851\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.58589 to 0.58509, saving model to /content/drive/MyDrive/30-days-of-ml-competition1/output/weights/Weights-017--0.58509.hdf5\n",
            "Epoch 18/50\n",
            "7500/7500 [==============================] - 47s 6ms/step - loss: 0.5892 - mean_absolute_error: 0.5892 - val_loss: 0.5889 - val_mean_absolute_error: 0.5889\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.58509\n",
            "Epoch 19/50\n",
            "7500/7500 [==============================] - 49s 7ms/step - loss: 0.5887 - mean_absolute_error: 0.5887 - val_loss: 0.5883 - val_mean_absolute_error: 0.5883\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.58509\n",
            "Epoch 20/50\n",
            "7500/7500 [==============================] - 49s 7ms/step - loss: 0.5893 - mean_absolute_error: 0.5893 - val_loss: 0.5896 - val_mean_absolute_error: 0.5896\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.58509\n",
            "Epoch 21/50\n",
            "7500/7500 [==============================] - 47s 6ms/step - loss: 0.5888 - mean_absolute_error: 0.5888 - val_loss: 0.5890 - val_mean_absolute_error: 0.5890\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.58509\n",
            "Epoch 22/50\n",
            "7500/7500 [==============================] - 48s 6ms/step - loss: 0.5890 - mean_absolute_error: 0.5890 - val_loss: 0.5964 - val_mean_absolute_error: 0.5964\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.58509\n",
            "Epoch 23/50\n",
            "7500/7500 [==============================] - 49s 7ms/step - loss: 0.5886 - mean_absolute_error: 0.5886 - val_loss: 0.5921 - val_mean_absolute_error: 0.5921\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.58509\n",
            "Epoch 24/50\n",
            "7500/7500 [==============================] - 49s 7ms/step - loss: 0.5887 - mean_absolute_error: 0.5887 - val_loss: 0.5857 - val_mean_absolute_error: 0.5857\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.58509\n",
            "Epoch 25/50\n",
            "7500/7500 [==============================] - 50s 7ms/step - loss: 0.5888 - mean_absolute_error: 0.5888 - val_loss: 0.5856 - val_mean_absolute_error: 0.5856\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.58509\n",
            "Epoch 26/50\n",
            "7500/7500 [==============================] - 49s 7ms/step - loss: 0.5883 - mean_absolute_error: 0.5883 - val_loss: 0.5911 - val_mean_absolute_error: 0.5911\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.58509\n",
            "Epoch 27/50\n",
            "7500/7500 [==============================] - 47s 6ms/step - loss: 0.5885 - mean_absolute_error: 0.5885 - val_loss: 0.5899 - val_mean_absolute_error: 0.5899\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.58509\n",
            "Epoch 28/50\n",
            "7500/7500 [==============================] - 46s 6ms/step - loss: 0.5883 - mean_absolute_error: 0.5883 - val_loss: 0.5867 - val_mean_absolute_error: 0.5867\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.58509\n",
            "Epoch 29/50\n",
            "7500/7500 [==============================] - 47s 6ms/step - loss: 0.5886 - mean_absolute_error: 0.5886 - val_loss: 0.5874 - val_mean_absolute_error: 0.5874\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.58509\n",
            "Epoch 30/50\n",
            "7500/7500 [==============================] - 47s 6ms/step - loss: 0.5883 - mean_absolute_error: 0.5883 - val_loss: 0.5872 - val_mean_absolute_error: 0.5872\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.58509\n",
            "Epoch 31/50\n",
            "7500/7500 [==============================] - 49s 6ms/step - loss: 0.5880 - mean_absolute_error: 0.5880 - val_loss: 0.5922 - val_mean_absolute_error: 0.5922\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.58509\n",
            "Epoch 32/50\n",
            "7500/7500 [==============================] - 47s 6ms/step - loss: 0.5884 - mean_absolute_error: 0.5884 - val_loss: 0.5888 - val_mean_absolute_error: 0.5888\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.58509\n",
            "Epoch 33/50\n",
            "7500/7500 [==============================] - 47s 6ms/step - loss: 0.5883 - mean_absolute_error: 0.5883 - val_loss: 0.5860 - val_mean_absolute_error: 0.5860\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.58509\n",
            "Epoch 34/50\n",
            "7500/7500 [==============================] - 47s 6ms/step - loss: 0.5881 - mean_absolute_error: 0.5881 - val_loss: 0.5880 - val_mean_absolute_error: 0.5880\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.58509\n",
            "Epoch 35/50\n",
            "7500/7500 [==============================] - 46s 6ms/step - loss: 0.5877 - mean_absolute_error: 0.5877 - val_loss: 0.5856 - val_mean_absolute_error: 0.5856\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.58509\n",
            "Epoch 36/50\n",
            "7500/7500 [==============================] - 46s 6ms/step - loss: 0.5882 - mean_absolute_error: 0.5882 - val_loss: 0.5901 - val_mean_absolute_error: 0.5901\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.58509\n",
            "Epoch 37/50\n",
            "7500/7500 [==============================] - 47s 6ms/step - loss: 0.5879 - mean_absolute_error: 0.5879 - val_loss: 0.6029 - val_mean_absolute_error: 0.6029\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.58509\n",
            "Epoch 38/50\n",
            "7500/7500 [==============================] - 51s 7ms/step - loss: 0.5885 - mean_absolute_error: 0.5885 - val_loss: 0.5860 - val_mean_absolute_error: 0.5860\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.58509\n",
            "Epoch 39/50\n",
            "7500/7500 [==============================] - 49s 7ms/step - loss: 0.5879 - mean_absolute_error: 0.5879 - val_loss: 0.5852 - val_mean_absolute_error: 0.5852\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.58509\n",
            "Epoch 40/50\n",
            "7500/7500 [==============================] - 48s 6ms/step - loss: 0.5881 - mean_absolute_error: 0.5881 - val_loss: 0.5865 - val_mean_absolute_error: 0.5865\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.58509\n",
            "Epoch 41/50\n",
            "7500/7500 [==============================] - 48s 6ms/step - loss: 0.5882 - mean_absolute_error: 0.5882 - val_loss: 0.5895 - val_mean_absolute_error: 0.5895\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.58509\n",
            "Epoch 42/50\n",
            "7500/7500 [==============================] - 47s 6ms/step - loss: 0.5879 - mean_absolute_error: 0.5879 - val_loss: 0.5880 - val_mean_absolute_error: 0.5880\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.58509\n",
            "Epoch 43/50\n",
            "7500/7500 [==============================] - 47s 6ms/step - loss: 0.5880 - mean_absolute_error: 0.5880 - val_loss: 0.5854 - val_mean_absolute_error: 0.5854\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.58509\n",
            "Epoch 44/50\n",
            "7500/7500 [==============================] - 48s 6ms/step - loss: 0.5879 - mean_absolute_error: 0.5879 - val_loss: 0.5873 - val_mean_absolute_error: 0.5873\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.58509\n",
            "Epoch 45/50\n",
            "7500/7500 [==============================] - 49s 7ms/step - loss: 0.5880 - mean_absolute_error: 0.5880 - val_loss: 0.5854 - val_mean_absolute_error: 0.5854\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.58509\n",
            "Epoch 46/50\n",
            "7500/7500 [==============================] - 49s 7ms/step - loss: 0.5875 - mean_absolute_error: 0.5875 - val_loss: 0.5852 - val_mean_absolute_error: 0.5852\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.58509\n",
            "Epoch 47/50\n",
            "7500/7500 [==============================] - 49s 7ms/step - loss: 0.5877 - mean_absolute_error: 0.5877 - val_loss: 0.5885 - val_mean_absolute_error: 0.5885\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.58509\n",
            "Epoch 48/50\n",
            "7500/7500 [==============================] - 46s 6ms/step - loss: 0.5878 - mean_absolute_error: 0.5878 - val_loss: 0.5857 - val_mean_absolute_error: 0.5857\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.58509\n",
            "Epoch 49/50\n",
            "7500/7500 [==============================] - 45s 6ms/step - loss: 0.5878 - mean_absolute_error: 0.5878 - val_loss: 0.5861 - val_mean_absolute_error: 0.5861\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.58509\n",
            "Epoch 50/50\n",
            "7500/7500 [==============================] - 48s 6ms/step - loss: 0.5879 - mean_absolute_error: 0.5879 - val_loss: 0.5896 - val_mean_absolute_error: 0.5896\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.58509\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1ad6b45510>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXWJR_52rUxu"
      },
      "source": [
        "X_test = pd.read_csv(TEST_DATA_PATH, index_col='id')\n",
        "X_test[cat_cnames] = ordinal_encode.transform(X_test[cat_cnames])\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "Ue9akaXi2rz7",
        "outputId": "041feafb-9776-445a-ea68-ac13a7213972"
      },
      "source": [
        "X_test"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cat0</th>\n",
              "      <th>cat1</th>\n",
              "      <th>cat2</th>\n",
              "      <th>cat3</th>\n",
              "      <th>cat4</th>\n",
              "      <th>cat5</th>\n",
              "      <th>cat6</th>\n",
              "      <th>cat7</th>\n",
              "      <th>cat8</th>\n",
              "      <th>cat9</th>\n",
              "      <th>cont0</th>\n",
              "      <th>cont1</th>\n",
              "      <th>cont2</th>\n",
              "      <th>cont3</th>\n",
              "      <th>cont4</th>\n",
              "      <th>cont5</th>\n",
              "      <th>cont6</th>\n",
              "      <th>cont7</th>\n",
              "      <th>cont8</th>\n",
              "      <th>cont9</th>\n",
              "      <th>cont10</th>\n",
              "      <th>cont11</th>\n",
              "      <th>cont12</th>\n",
              "      <th>cont13</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.296227</td>\n",
              "      <td>0.686757</td>\n",
              "      <td>0.587731</td>\n",
              "      <td>0.392753</td>\n",
              "      <td>0.476739</td>\n",
              "      <td>0.376350</td>\n",
              "      <td>0.337884</td>\n",
              "      <td>0.321832</td>\n",
              "      <td>0.445212</td>\n",
              "      <td>0.290258</td>\n",
              "      <td>0.244476</td>\n",
              "      <td>0.087914</td>\n",
              "      <td>0.301831</td>\n",
              "      <td>0.845702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.543707</td>\n",
              "      <td>0.364761</td>\n",
              "      <td>0.452967</td>\n",
              "      <td>0.929645</td>\n",
              "      <td>0.285509</td>\n",
              "      <td>0.860046</td>\n",
              "      <td>0.798712</td>\n",
              "      <td>0.835961</td>\n",
              "      <td>0.391657</td>\n",
              "      <td>0.288276</td>\n",
              "      <td>0.549568</td>\n",
              "      <td>0.905097</td>\n",
              "      <td>0.850684</td>\n",
              "      <td>0.693940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.408961</td>\n",
              "      <td>0.296129</td>\n",
              "      <td>0.690999</td>\n",
              "      <td>0.740027</td>\n",
              "      <td>0.697272</td>\n",
              "      <td>0.683600</td>\n",
              "      <td>0.404089</td>\n",
              "      <td>0.879379</td>\n",
              "      <td>0.275549</td>\n",
              "      <td>0.427871</td>\n",
              "      <td>0.491667</td>\n",
              "      <td>0.384315</td>\n",
              "      <td>0.376689</td>\n",
              "      <td>0.508099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.031239</td>\n",
              "      <td>0.356062</td>\n",
              "      <td>0.303651</td>\n",
              "      <td>0.895591</td>\n",
              "      <td>0.719306</td>\n",
              "      <td>0.777890</td>\n",
              "      <td>0.730954</td>\n",
              "      <td>0.644315</td>\n",
              "      <td>1.024017</td>\n",
              "      <td>0.391090</td>\n",
              "      <td>0.988340</td>\n",
              "      <td>0.411828</td>\n",
              "      <td>0.393585</td>\n",
              "      <td>0.461372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.530447</td>\n",
              "      <td>0.729004</td>\n",
              "      <td>0.281723</td>\n",
              "      <td>0.444698</td>\n",
              "      <td>0.313032</td>\n",
              "      <td>0.431007</td>\n",
              "      <td>0.390992</td>\n",
              "      <td>0.408874</td>\n",
              "      <td>0.447887</td>\n",
              "      <td>0.390253</td>\n",
              "      <td>0.648932</td>\n",
              "      <td>0.385935</td>\n",
              "      <td>0.370401</td>\n",
              "      <td>0.900412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499987</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.505445</td>\n",
              "      <td>0.710839</td>\n",
              "      <td>0.225285</td>\n",
              "      <td>0.932926</td>\n",
              "      <td>0.287454</td>\n",
              "      <td>0.543800</td>\n",
              "      <td>0.682378</td>\n",
              "      <td>1.028978</td>\n",
              "      <td>1.022741</td>\n",
              "      <td>0.683903</td>\n",
              "      <td>0.877273</td>\n",
              "      <td>0.532410</td>\n",
              "      <td>0.605397</td>\n",
              "      <td>0.884581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499990</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.350751</td>\n",
              "      <td>0.887132</td>\n",
              "      <td>0.346864</td>\n",
              "      <td>0.284264</td>\n",
              "      <td>0.794881</td>\n",
              "      <td>0.432778</td>\n",
              "      <td>0.389775</td>\n",
              "      <td>0.359871</td>\n",
              "      <td>0.550013</td>\n",
              "      <td>0.492082</td>\n",
              "      <td>0.202295</td>\n",
              "      <td>0.416875</td>\n",
              "      <td>0.406205</td>\n",
              "      <td>0.758665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499991</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.378393</td>\n",
              "      <td>0.549489</td>\n",
              "      <td>0.411319</td>\n",
              "      <td>0.437275</td>\n",
              "      <td>0.514487</td>\n",
              "      <td>0.060997</td>\n",
              "      <td>0.171741</td>\n",
              "      <td>0.317185</td>\n",
              "      <td>0.150340</td>\n",
              "      <td>0.122109</td>\n",
              "      <td>0.390524</td>\n",
              "      <td>0.334026</td>\n",
              "      <td>0.378987</td>\n",
              "      <td>0.839416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499994</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.014149</td>\n",
              "      <td>0.430139</td>\n",
              "      <td>0.067896</td>\n",
              "      <td>0.393523</td>\n",
              "      <td>0.286144</td>\n",
              "      <td>1.061710</td>\n",
              "      <td>0.819811</td>\n",
              "      <td>0.901241</td>\n",
              "      <td>0.555339</td>\n",
              "      <td>0.844315</td>\n",
              "      <td>0.894193</td>\n",
              "      <td>0.794102</td>\n",
              "      <td>0.844279</td>\n",
              "      <td>0.890473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499995</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.631521</td>\n",
              "      <td>0.355393</td>\n",
              "      <td>0.922337</td>\n",
              "      <td>0.769672</td>\n",
              "      <td>0.286755</td>\n",
              "      <td>1.065725</td>\n",
              "      <td>0.687682</td>\n",
              "      <td>0.654738</td>\n",
              "      <td>0.574575</td>\n",
              "      <td>0.617467</td>\n",
              "      <td>0.694336</td>\n",
              "      <td>0.745698</td>\n",
              "      <td>0.568525</td>\n",
              "      <td>0.783568</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200000 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        cat0  cat1  cat2  cat3  ...    cont10    cont11    cont12    cont13\n",
              "id                              ...                                        \n",
              "0        1.0   1.0   1.0   2.0  ...  0.244476  0.087914  0.301831  0.845702\n",
              "5        0.0   1.0   0.0   2.0  ...  0.549568  0.905097  0.850684  0.693940\n",
              "15       1.0   0.0   0.0   0.0  ...  0.491667  0.384315  0.376689  0.508099\n",
              "16       1.0   1.0   0.0   2.0  ...  0.988340  0.411828  0.393585  0.461372\n",
              "17       1.0   1.0   0.0   2.0  ...  0.648932  0.385935  0.370401  0.900412\n",
              "...      ...   ...   ...   ...  ...       ...       ...       ...       ...\n",
              "499987   1.0   0.0   0.0   2.0  ...  0.877273  0.532410  0.605397  0.884581\n",
              "499990   1.0   0.0   0.0   2.0  ...  0.202295  0.416875  0.406205  0.758665\n",
              "499991   0.0   1.0   1.0   2.0  ...  0.390524  0.334026  0.378987  0.839416\n",
              "499994   0.0   0.0   0.0   2.0  ...  0.894193  0.794102  0.844279  0.890473\n",
              "499995   0.0   0.0   0.0   2.0  ...  0.694336  0.745698  0.568525  0.783568\n",
              "\n",
              "[200000 rows x 24 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmXT7HFn0xzA"
      },
      "source": [
        "# predictions \n",
        "predictions = model.predict(X_test)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA5Y7-wCez1a"
      },
      "source": [
        "def output_submission(prediction, file_name):\n",
        "    \"\"\"creating a kaggle submission file\n",
        "\n",
        "    Args:\n",
        "        prediction (array): an array of predictions of the test dataset\n",
        "        file_name (string): a string for the name without the extension\n",
        "    \"\"\"\n",
        "    my_submission = pd.DataFrame({'target': predictions[:,0]},\n",
        "                                 index=X_test.index)\n",
        "    #my_submission.set_index('id')\n",
        "    file_path = os.path.join(OUTPUT_PATH,file_name)\n",
        "    my_submission.to_csv(f'{file_path}.csv')\n",
        "    print(f'A submission file has been made at {file_path}')"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OG9Zi4jc062i",
        "outputId": "7e1cdec8-7219-4376-802d-110246ffcdb8"
      },
      "source": [
        "output_submission(predictions, \"DL_submission\")"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A submission file has been made at /content/drive/MyDrive/30-days-of-ml-competition1/output/DL_submission\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "Zm_ICv5O3IvE",
        "outputId": "3800af4e-505a-4bae-c035-1280a8e5a2b4"
      },
      "source": [
        "pd.DataFrame({'id':X_test.index, 'target':predictions})"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-6534c5af3b61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         ]\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_homogenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_homogenize\u001b[0;34m(data, index, dtype)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_multiget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             val = sanitize_array(\n\u001b[0;32m--> 352\u001b[0;31m                 \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m             )\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data must be 1-dimensional\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray_tuplesafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: Data must be 1-dimensional"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8F-InoK3Opw",
        "outputId": "abd244ac-9a74-4d7d-928f-4eb378f6768e"
      },
      "source": [
        "predictions.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "yt-WIxJ_3aQw",
        "outputId": "0e1af38d-f875-4d42-f850-db0c47b795c3"
      },
      "source": [
        ""
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.172789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>8.284880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>8.342461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>8.239244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>8.282663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499987</th>\n",
              "      <td>8.257453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499990</th>\n",
              "      <td>8.263576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499991</th>\n",
              "      <td>8.338556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499994</th>\n",
              "      <td>8.269198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499995</th>\n",
              "      <td>8.284880</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          target\n",
              "id              \n",
              "0       8.172789\n",
              "5       8.284880\n",
              "15      8.342461\n",
              "16      8.239244\n",
              "17      8.282663\n",
              "...          ...\n",
              "499987  8.257453\n",
              "499990  8.263576\n",
              "499991  8.338556\n",
              "499994  8.269198\n",
              "499995  8.284880\n",
              "\n",
              "[200000 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J3PeDa53mwf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}